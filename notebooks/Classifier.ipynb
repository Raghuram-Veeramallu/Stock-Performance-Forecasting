{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyO90FG1sSpiH1tN8dgGWCDE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Model Evaluator/Model Trainer\n","\n","This notebook is used to train and evaluate the ability of our model to forecast volatility based on summarized transcript inputs."],"metadata":{"id":"JaCquBUjFFCe"}},{"cell_type":"markdown","source":["## Dependencies"],"metadata":{"id":"5wvfwur4FRXk"}},{"cell_type":"markdown","source":["### Virtual Environment Dependencies\n","\n","The model evaluator leverages the huggingface library. The following packages must be installed:\n","\n","1. transformers\n","2. datasets\n","3. evaluate\n","4. torchmetrics"],"metadata":{"id":"11rxjPwCrViQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcdTJCd2FEQC"},"outputs":[],"source":["!pip install transformers datasets evaluate torchmetrics"]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"A4F9WPW4riBC"}},{"cell_type":"code","source":["import torch\n","from datasets import load_dataset, Dataset, DatasetDict\n","from google.colab import drive, runtime\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n","import torchmetrics\n","from tqdm import tqdm\n","import os\n","import datetime\n","import plotly.express as px\n","import pandas\n","import numpy as np\n","from collections import Counter\n","import sqlite3 as sq\n","from dataclasses import dataclass\n","from typing import Dict, List, Tuple, Callable\n","import evaluate\n"],"metadata":{"id":"MlHEP8zVFSON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"id":"H8FDzOGcoFFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"DdNjauiGFs5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paths\n","\n","This notebook requires a connection with the database containing all of the transcript data and the labels. This can be generated by running the FinancialModelPrep [notebook](https://colab.research.google.com/drive/1IPQLXCfiAfVXH-W30vYevktjQZnV6qt6?usp=sharing) notebook to create the database and pull the financial data along with the Summary [notebook](https://colab.research.google.com/drive/1Jv0knYxpoCyexYn6yA6TSIxOsX9nJY5L?usp=sharing) to summarize the transcripts."],"metadata":{"id":"D0pWLldSFdaJ"}},{"cell_type":"code","source":["project_path = \"/content/drive/MyDrive/CSCI-5541/Project/\"\n","data_path = os.path.join(project_path, \"data\")\n","model_path = os.path.join(project_path,\"model\")\n","classification_model_path = os.path.join(model_path,\"classification\")\n","tokenizer_base_path = os.path.join(project_path, \"tokenizer\")\n","fine_tuned_model_base_path = os.path.join(model_path, \"fine_tuned_classification\")"],"metadata":{"id":"-4ZWkgNZFcQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["database_path = os.path.join(data_path, \"earnings_transcripts_data.db\")"],"metadata":{"id":"eltHUmpUFmjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists(classification_model_path):\n","    os.makedirs(classification_model_path)\n","if not os.path.exists(tokenizer_base_path):\n","    os.makedirs(tokenizer_base_path)\n","if not os.path.exists(fine_tuned_model_base_path):\n","    os.makedirs(fine_tuned_model_base_path)"],"metadata":{"id":"xHQGTV4EFoKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Classes and DB Util"],"metadata":{"id":"3GFilH6wJbwh"}},{"cell_type":"markdown","source":["### Data Classes\n","\n","Objects to hold data from tables"],"metadata":{"id":"R1mk5htXJoxk"}},{"cell_type":"code","source":["@dataclass\n","class Company:\n","    symbol: str\n","\n","    def to_dict(self):\n","        return {\n","            \"symbol\": self.symbol\n","        }\n","\n","@dataclass\n","class Transcript:\n","    symbol: str\n","    date: str\n","    year: int\n","    quarter: int\n","    transcript: str\n","\n","    def to_dict(self):\n","        return {\n","            \"symbol\": self.symbol,\n","            \"date\": self.date,\n","            \"year\": self.year,\n","            \"quarter\": self.quarter,\n","            \"transcript\": self.transcript\n","        }\n","\n","\n","@dataclass\n","class Price:\n","    symbol: str\n","    date: str\n","    opening_price: float\n","    closing_price: float\n","\n","    def to_dict(self):\n","        return {\n","            \"symbol\": self.symbol,\n","            \"date\": self.date,\n","            \"opening_price\": self.opening_price,\n","            \"closing_price\": self.closing_price,\n","        }\n","\n","@dataclass\n","class Label:\n","    id: int\n","    symbol: str\n","    transcript_date: str\n","    price_day_of_meeting: float\n","    avg_value: float\n","    delta_days: int\n","    total_days: int\n","    avg_type: str\n","    label: str\n","\n","\n","@dataclass\n","class Predicted_Label:\n","    id: int\n","    true_label_id: int\n","    symbol: str\n","    transcript_date: str\n","    label: str\n","    summarization_method: str\n","    classification_method: str\n","    true_label_id: int\n","\n","@dataclass\n","class TranscriptSummary:\n","    symbol: str\n","    date: str\n","    year: int\n","    quarter: int\n","    summarized_transcript: str\n","    summarization_method: str\n","\n","    def to_dict(self):\n","        return {\n","            \"symbol\": self.symbol,\n","            \"date\": self.date,\n","            \"year\": self.year,\n","            \"quarter\": self.quarter,\n","            \"summarized_transcript\": self.summarized_transcript,\n","            \"summarization_method\": self.summarization_method,\n","        }"],"metadata":{"id":"lmb3ylSTFpG9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DB Util\n","Utility for interacting with the database"],"metadata":{"id":"1GKdMVdHJqwK"}},{"cell_type":"code","source":["class DB_Util:\n","    def __init__(self, database_path: str):\n","        self.con = sq.connect(database_path)\n","\n","    \n","    def create_or_drop_table(self, sql: str) -> bool:\n","        cursor = self.con.cursor()\n","        try:\n","            cursor.execute(\n","                sql,\n","            )\n","            return True\n","        except Exception as e:\n","            print(e)\n","            return False\n","        finally:\n","            self.con.commit()\n","            cursor.close()\n","            del cursor\n","\n","    def execute_query(self, sql: str, args: List) -> List:\n","        cursor = self.con.cursor()\n","        try:\n","            query_results = cursor.execute(\n","                sql,\n","                args\n","            )\n","            return query_results.fetchall()\n","        except Exception as e:\n","            print(e)\n","            return []\n","        finally:\n","            cursor.close()\n","            del cursor\n","\n","\n","    def insert_data(self, sql: str, data: List) -> bool:\n","        cursor = self.con.cursor()\n","        try:\n","            cursor.execute(\n","                sql,\n","                data                \n","            )\n","            return True\n","        except Exception as e:\n","            print(e)\n","            return False\n","        finally:\n","            self.con.commit()\n","            cursor.close()\n","            del cursor\n","    \n","    def close_connection(self):\n","        self.con.close()\n","        del self.con"],"metadata":{"id":"D1dHdXkPJqTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Database Connection and Operations"],"metadata":{"id":"liXHeEWIJ1fJ"}},{"cell_type":"markdown","source":["### Create Database Connection\n","In order to interact with the database, simply pass the path to the database to the constructor."],"metadata":{"id":"c17dCeoZK6Gf"}},{"cell_type":"code","source":["db_util = DB_Util(database_path=database_path)"],"metadata":{"id":"Jq37K-rcKjlT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create Predictions Table"],"metadata":{"id":"1PisX-lpK-Ng"}},{"cell_type":"code","source":["table_definitions = [\n","    '''\n","    CREATE TABLE IF NOT EXISTS transcript_prediction(\n","        symbol CHAR[10] NOT NULL,\n","        year INTEGER,\n","        quarter INTEGER,\n","        date CHAR[10],\n","        summarization_method CHAR[80],\n","        classification_method CHAR[80],\n","        predicted_class CHAR[20],\n","        true_label_id INTEGER,\n","        FOREIGN KEY (symbol) REFERENCES company(symbol),\n","        FOREIGN KEY (true_label_id) REFERENCES label(id)\n","        PRIMARY KEY(symbol, year, quarter, date, summarization_method, classification_method, true_label_id)\n","    )    \n","    '''\n","]\n","\n","table_creation_status = [\n","    db_util.create_or_drop_table(\n","        sql=table_definition\n","    )\n","    for table_definition in table_definitions\n","]\n","print(table_creation_status)"],"metadata":{"id":"4sNOSttqLwge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# db_util.create_or_drop_table(\n","#     '''\n","#     DROP TABLE IF EXISTS transcript_prediction \n","#     '''    \n","# )"],"metadata":{"id":"iHFg2lGcNEPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Queries\n","Useful queries"],"metadata":{"id":"zpGbvNBTJ5d-"}},{"cell_type":"code","source":["def fetch_all_transcripts(db_util: DB_Util) -> List[Transcript]:\n","    transcript_records = db_util.execute_query(\n","        \"SELECT * FROM transcript WHERE ?\",\n","        [True]\n","    )\n","    return [\n","        Transcript(\n","            symbol=transcript_record[0],\n","            year=transcript_record[1],\n","            quarter=transcript_record[2],\n","            date=transcript_record[3],\n","            transcript=transcript_record[4],\n","        )\n","        for transcript_record in transcript_records\n","    ]\n","\n","def fetch_transcript_by_company(db_util: DB_Util, company: str) -> List[Transcript]:\n","    transcript_records = db_util.execute_query(\n","        \"SELECT * FROM transcript WHERE symbol = ?\",\n","        [company]\n","    )\n","    return [\n","        Transcript(\n","            symbol=transcript_record[0],\n","            year=transcript_record[1],\n","            quarter=transcript_record[2],\n","            date=transcript_record[3],\n","            transcript=transcript_record[4],\n","        )\n","        for transcript_record in transcript_records\n","    ]\n","\n","def fetch_all_summaries(db_util: DB_Util) -> List[Transcript]:\n","    transcript_records = db_util.execute_query(\n","        \"SELECT * FROM transcript_summary WHERE ?\",\n","        [True]\n","    )\n","    return [\n","        TranscriptSummary(\n","            symbol=transcript_record[0],\n","            year=transcript_record[1],\n","            quarter=transcript_record[2],\n","            date=transcript_record[3],\n","            summarized_transcript=transcript_record[4],\n","            summarization_method=transcript_record[5],\n","        )\n","        for transcript_record in transcript_records\n","    ]\n","\n","\n","def fetch_summaries_by_method(db_util: DB_Util, method: str) -> List[Transcript]:\n","    transcript_records = db_util.execute_query(\n","        \"SELECT * FROM transcript_summary WHERE summarization_method = ?\",\n","        [method]\n","    )\n","    return [\n","        TranscriptSummary(\n","            symbol=transcript_record[0],\n","            year=transcript_record[1],\n","            quarter=transcript_record[2],\n","            date=transcript_record[3],\n","            summarized_transcript=transcript_record[4],\n","            summarization_method=transcript_record[5],\n","        )\n","        for transcript_record in transcript_records\n","    ]\n","\n","\n","def fetch_summaries_by_company_and_method(db_util: DB_Util, company: str, method: str) -> List[Transcript]:\n","    transcript_records = db_util.execute_query(\n","        \"SELECT * FROM transcript_summary WHERE symbol = ? and summarization_method = ?\",\n","        [company, method]\n","    )\n","    return [\n","        TranscriptSummary(\n","            symbol=transcript_record[0],\n","            year=transcript_record[1],\n","            quarter=transcript_record[2],\n","            date=transcript_record[3],\n","            summarized_transcript=transcript_record[4],\n","            summarization_method=transcript_record[5],\n","        )\n","        for transcript_record in transcript_records\n","    ]\n"],"metadata":{"id":"Yr4jyh9cJv8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create Dataset\n","\n","Huggingface supports conversion of databases into datasets. The cells below are used to construct a dataset by leveraging this functionality."],"metadata":{"id":"XROLNacKOC7-"}},{"cell_type":"code","source":["summarization_methods = db_util.execute_query(\n","    '''\n","    SELECT DISTINCT(summarization_method) FROM transcript_summary t\n","    ''', \n","    []\n",")"],"metadata":{"id":"JN-8I-QYKdds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for summarization_method in summarization_methods:\n","    print(summarization_method[0])"],"metadata":{"id":"cByL9OF-ouKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summarization_method = \"human-centered-summarization/financial-summarization-pegasus-10-stride-10\""],"metadata":{"id":"3Y67mwq6pEbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds = Dataset.from_sql(\n","    f'SELECT t.symbol, t.summarized_transcript, t.date, t.year, l.label FROM transcript_summary t, label l where t.symbol = l.symbol and t.date = l.transcript_date and l.avg_type = \"STANDARDDEVIATION2CLASS\" and t.summarization_method=\"{summarization_method}\"',\n","    con=db_util.con\n",")\n"],"metadata":{"id":"OZFLS9WnPDge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds"],"metadata":{"id":"C0fi8Ml_zL9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading model and tokenizer\n","The cells below are used to download and save the model and tokenizer for the experiment. This approach allows caching as well by saving the model and tokenizer locally. "],"metadata":{"id":"0hkm0DPBVLy-"}},{"cell_type":"code","source":["# base_name = \"DunnBC22/distilbert-base-uncased-Financial_Sentiment_Analysis\"\n","base_name = \"Svetlana0303/Classfication_longformer\""],"metadata":{"id":"hQgbYIIhWKC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model_tokenizer(name: str, tokenizer_dir: str, model_dir: str, total_classes: int):\n","    tokenizer_path = os.path.join(tokenizer_dir, name)\n","    model_path = os.path.join(model_dir, name)\n","\n","    if os.path.exists(tokenizer_path) and os.listdir(tokenizer_path) != []:\n","        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n","    else:\n","        tokenizer = AutoTokenizer.from_pretrained(name)\n","        tokenizer.save_pretrained(tokenizer_path)\n","    \n","\n","    if os.path.exists(model_path) and os.listdir(model_path) != []:\n","        model = AutoModelForSequenceClassification.from_pretrained(model_path, torchscript=True, num_labels=total_classes, ignore_mismatched_sizes=True)\n","    else:\n","        model = AutoModelForSequenceClassification.from_pretrained(name, torchscript=True, num_labels=total_classes, ignore_mismatched_sizes=True)\n","        model.save_pretrained(model_path)\n","    return tokenizer, model\n"],"metadata":{"id":"q3Aak0I-WYOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer, model = load_model_tokenizer(base_name, tokenizer_base_path, classification_model_path, 2)"],"metadata":{"id":"XUEoZ5QdUsJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"XMbMhdfZoIxn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing Dataset\n","We are currently running 2 different types of experiments:\n","1. Testing model generalizablity. This approach divides the dataset into training test splits based on companies. If a model is able to accurately forecast the volatility, this supports that the approach generalizes well.\n","2. Test model ability to forecast for a given company. This approach splits the dataset into training test split based on year. If a model is able to accurately forecast under these conditions, it supports the claim that we may be able to train company specific models. "],"metadata":{"id":"8vO5QEE5YT9X"}},{"cell_type":"code","source":["label_map = {\n","  \"VOLATILE\": 0,\n","  \"NOT VOLATILE\": 1\n","}\n","\n","training_set_companies = [\n","    \"AAPL\",\n","    \"MSFT\",\n","    \"AMZN\",\n","    \"NVDA\",\n","    \"GOOGL\",\n","    \"GOOG\",\n","    \"BRK.B\",\n","    \"TSLA\",\n","    \"META\",\n","    \"UNH\",\n","    \"XOM\",\n","    \"JNJ\",\n","    \"JPM\",\n","    \"V\",\n","    \"PG\",\n","    \"MA\"\n","]\n","\n","training_set_years = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]"],"metadata":{"id":"XI4n76ZOd06g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_function(batch):\n","    tokenized_batch = tokenizer(batch[\"summarized_transcript\"], padding=\"max_length\", truncation=True)\n","    tokenized_batch[\"label\"] = [label_map[label] for label in batch[\"label\"]]\n","    return tokenized_batch"],"metadata":{"id":"O47lUeVLXrA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_ds = ds.map(tokenize_function, batched=True)"],"metadata":{"id":"qEv1fmqtaIX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def divide_dataset(dataset, filter_type:str, filter_list: list):\n","    training_set = tokenized_ds.filter(lambda x: x[filter_type] in filter_list)\n","    test_set = tokenized_ds.filter(lambda x: x[filter_type] not in filter_list)\n","    return training_set, test_set"],"metadata":{"id":"mnMj1E6QpWgz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_set, test_set = divide_dataset(ds, \"year\", training_set_years)\n","# training_set, test_set = divide_dataset(ds, \"symbol\", training_set_companies)\n"],"metadata":{"id":"dOnCRU5GaM4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_set, test_set"],"metadata":{"id":"r1vOShj7yWgN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Finetune model\n","Run the cells below to finetune the model. "],"metadata":{"id":"0rh2WoyVaop-"}},{"cell_type":"code","source":["finetuned_model_path = os.path.join(fine_tuned_model_base_path, base_name)"],"metadata":{"id":"YDZG31wLbfKN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Args\n","\n","Arguments for training. Due to memory related limitations, batches must be limited to 2 instances at most."],"metadata":{"id":"LzPD_VxpbsxW"}},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=finetuned_model_path,\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=2,\n","    # per_device_eval_batch_size=2,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"],"metadata":{"id":"VsIMMpIJan_7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Metrics"],"metadata":{"id":"QqxjMWjObwnU"}},{"cell_type":"code","source":["accuracy = evaluate.load(\"accuracy\")"],"metadata":{"id":"fV9CnqZ9b4Oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return accuracy.compute(predictions=predictions, references=labels)"],"metadata":{"id":"_rLoC1Yaaln1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"0LxykAOe2JiM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Finetuning\n","\n","The cells below are used to finetune the model generated above. Due to our dataset being limited in size, we do not create a validation set. Due to the HuggingFace Trainer requiring an evaluation dataset, we pass the training set."],"metadata":{"id":"M3godnlfc1wl"}},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=training_set,\n","    compute_metrics=compute_metrics,\n","    eval_dataset=training_set,\n",")"],"metadata":{"id":"WofH1oeIcOdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"QfprrNICdLWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.save_model(os.path.join(finetuned_model_path,\"baseline_2\"))"],"metadata":{"id":"zuNyz_2yrq25"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation\n","The cells below are used to assess the model on the test set."],"metadata":{"id":"AxHVr4g6qv_z"}},{"cell_type":"code","source":["results = trainer.predict(test_set)"],"metadata":{"id":"RgCQnesxfrQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_labels = torch.tensor(results.label_ids)"],"metadata":{"id":"IpfnN9F5ppJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_label = torch.argmax(torch.tensor(results.predictions), dim=1)"],"metadata":{"id":"PTGpQJ_dprEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=2)"],"metadata":{"id":"8Knlet5iqQQm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results.metrics"],"metadata":{"id":"RDukExmqq0oa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(predicted_label, true_labels)"],"metadata":{"id":"kCsOiqhIq1Ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.model_max_length"],"metadata":{"id":"RiKCufK2IdEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["runtime.unassign()"],"metadata":{"id":"vg4pL0QsrCy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z0erXicaKokV"},"execution_count":null,"outputs":[]}]}